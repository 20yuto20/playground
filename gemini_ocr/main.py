import os
import google.generativeai as genai
from dotenv import load_dotenv
from pdf2image import convert_from_path
from PIL import Image, ImageDraw, ImageFont
import pytesseract
import json
import io
import base64
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
import random

load_dotenv()

genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# ãƒ¢ãƒ‡ãƒ«ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
generation_config = {
    "temperature": 0.0
}

# ãƒ¢ãƒ‡ãƒ«åã‚’æ¨å¥¨ã•ã‚ŒãŸãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«å¤‰æ›´
model_name = "models/gemini-2.5-pro-preview-03-25"

# å¿…è¦ã§ã‚ã‚Œã°safetyã‚’è¨­å®šï¼ˆä»Šå›ã¯ãªã—ï¼‰
model = genai.GenerativeModel(
    model_name=model_name,
    generation_config=generation_config,
    safety_settings=None,
)

# ãƒ†ã‚­ã‚¹ãƒˆä½ç½®æ¤œå‡ºç”¨ã®ã‚·ã‚¹ãƒ†ãƒ æŒ‡ç¤º
text_detection_system_instructions = """
    ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’JSONã‚¢ãƒ¬ã‚¤ã¨ã—ã¦è¿”ã—ã¦ãã ã•ã„ã€‚ã‚³ãƒ¼ãƒ‰ãƒ•ã‚§ãƒ³ã‚¹ã‚„ãƒã‚¹ã‚¯ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚25å€‹ã¾ã§ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã«åˆ¶é™ã—ã¾ã™ã€‚
    å„ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã«ã¯ 'label' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ãã®ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’å«ã‚ã€'box_2d' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«ä½ç½®æƒ…å ±ã‚’å«ã‚ã¦ãã ã•ã„ã€‚
    ä½ç½®æƒ…å ±ã¯ [y1, x1, y2, x2] ã®å½¢å¼ã§ã€åº§æ¨™ã¯1000ã§æ­£è¦åŒ–ã•ã‚Œã¦ã„ã¾ã™ï¼ˆ0ã‹ã‚‰1000ã®ç¯„å›²ï¼‰ã€‚
"""

def parse_json(json_output):
    """JSONã®å‡ºåŠ›ã‹ã‚‰ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ•ã‚§ãƒ³ã‚·ãƒ³ã‚°ã‚’å‰Šé™¤ã™ã‚‹"""
    lines = json_output.splitlines()
    for i, line in enumerate(lines):
        if line == "```json":
            json_output = "\n".join(lines[i+1:])  # "```json"ã®å‰ã®ã™ã¹ã¦ã‚’å‰Šé™¤
            json_output = json_output.split("```")[0]  # é–‰ã˜ã‚‹"```"å¾Œã®ã™ã¹ã¦ã‚’å‰Šé™¤
            break
    return json_output

def pdf_to_images(pdf_path, output_folder, dpi=600):
    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # PDFã‹ã‚‰ç”»åƒã«å¤‰æ›ï¼ˆé«˜è§£åƒåº¦è¨­å®šï¼‰
    images = convert_from_path(pdf_path, dpi=dpi)

    # ä¿å­˜å‰ã«ç”»åƒå‡¦ç†ã‚’è¿½åŠ 
    image_paths = []
    for i, image in enumerate(images):
        # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·åŒ–ã¨äºŒå€¤åŒ–å‡¦ç†ã‚’è¿½åŠ 
        enhanced_image = enhance_image_for_ocr(image)
        image_path = os.path.join(output_folder, f"test_page_{i+1}.jpg")
        enhanced_image.save(image_path, "JPEG", quality=95)  # é«˜å“è³ªã§ä¿å­˜
        image_paths.append(image_path)
    
    return image_paths

def enhance_image_for_ocr(image):
    """æ•°å€¤èªè­˜ã«ç‰¹åŒ–ã—ãŸç”»åƒå‡¦ç†ã‚’è¡Œã†"""
    import cv2
    import numpy as np
    from PIL import Image, ImageEnhance

    # ç”»åƒã‚’numpyé…åˆ—ã«å¤‰æ›
    image_array = np.array(image)
    
    # ã‚°ãƒ¬ãƒ¼ã‚¹ã‚±ãƒ¼ãƒ«å¤‰æ›
    image_array = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)

    # ãƒã‚¤ã‚ºé™¤å»
    image_array = cv2.GaussianBlur(image_array, (5, 5), 0)

    # 2å€¤åŒ–
    _, image_array = cv2.threshold(image_array, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)

    # ã‚³ãƒ³ãƒˆãƒ©ã‚¹ãƒˆå¼·èª¿
    image_array = cv2.convertScaleAbs(image_array, alpha=1.5, beta=0)

    # numpyé…åˆ—ã‚’PILç”»åƒã«å¤‰æ›
    image = Image.fromarray(image_array)
    
    return image

# å¤§è¦æ¨¡ãªPDFã®ãƒãƒƒãƒå‡¦ç†
def batch_pdf_to_images(image_paths, batch_size=10):  #ã€€ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯é©å®œèª¿æ•´ï¼
    """ç”»åƒã‚’ãƒãƒƒãƒã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–"""
    for i in range(0, len(image_paths), batch_size):
        batch = image_paths[i:i+batch_size]
        yield batch

def extract_text_with_pytesseract(image):
    """pytesseractã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã™ã‚‹"""
    # æ—¥æœ¬èªOCRã®è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
    custom_config = r'--oem 3 --psm 6 -l jpn'
    text = pytesseract.image_to_string(image, config=custom_config)
    return text

def detect_text_boxes(image_paths):
    """ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã®ãƒ†ã‚­ã‚¹ãƒˆã®ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œå‡ºã™ã‚‹"""
    images = [Image.open(path) for path in image_paths]
    
    # ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ã‚¹ãƒˆãƒ©ã‚¯ã‚·ãƒ§ãƒ³ã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«çµ„ã¿è¾¼ã‚€
    prompt = f"""
    {text_detection_system_instructions}
    
    ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå†…ã®ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œå‡ºã—ã€å„ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ã¨ãã®ä½ç½®ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚
    """
    
    response = model.generate_content(
        prompt,
        *images,
        generation_config={"temperature": 0.2},
    )
    
    # JSONã‚’ãƒ‘ãƒ¼ã‚¹
    try:
        text_boxes = json.loads(parse_json(response.text))
        return text_boxes
    except json.JSONDecodeError as e:
        print(f"JSONãƒ‡ã‚³ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {e}")
        print(f"å—ä¿¡ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ: {response.text}")
        return []

def ocr_with_gemini(image_paths, instruction):
    """geminiã§ã®ç”»åƒå‡¦ç†ï¼ˆpytesseractã®çµæœã‚‚åˆ©ç”¨ï¼‰"""
    print(f"ç”»åƒã®ãƒ‘ã‚¹ï¼š{image_paths}")
    images = [Image.open(path) for path in image_paths]
    print(images)
    
    # pytesseractã‚’ä½¿ç”¨ã—ã¦äº‹å‰ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
    pytesseract_results = []
    for image in images:
        text = extract_text_with_pytesseract(image)
        pytesseract_results.append(text)
    
    # æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«å«ã‚ã‚‹
    pytesseract_text = "\n\n".join(pytesseract_results)
    
    # å…¥åŠ›å½¢å¼ã¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä¿®æ­£
    prompt = f"""
    {instruction}
    
    pytesseractã«ã‚ˆã‚‹äº‹å‰æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆ:
    {pytesseract_text}
    
    ä¸Šè¨˜ã®äº‹å‰æŠ½å‡ºãƒ†ã‚­ã‚¹ãƒˆã‚’å‚è€ƒã«ã—ã¦ã€æ­£ç¢ºãªãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
    """
    
    # APIã‚³ãƒ¼ãƒ«ã‚’ä¿®æ­£ã—ã¦å®‰å…¨ã«ã™ã‚‹
    try:
        response = model.generate_content(prompt, *images)
        extracted_text = response.text
        
        # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’æ¤œå‡º
        text_boxes = detect_text_boxes(image_paths)
        
        return {
            "extracted_text": extracted_text,
            "text_boxes": text_boxes
        }
    except Exception as e:
        print(f"APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
        return {
            "extracted_text": pytesseract_text,
            "text_boxes": []
        }

# è¤‡é›‘ãªãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¸ã®å¯¾å¿œï¼ˆä¸å‹•ç”£ãƒ¬ãƒãƒ¼ãƒˆã®ã‚°ãƒ©ãƒ•ãªã©ï¼‰
def ocr_complex_document(image_paths):
    instruction = """
    ã“ã‚Œã‚‰ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒšãƒ¼ã‚¸ã‹ã‚‰ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ã€‚

    ãƒ†ãƒ¼ãƒ–ãƒ«ã®å ´åˆï¼š
    1. ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã‚’ä½¿ç”¨ã—ã¦ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’ç¶­æŒ
    2. ã™ã¹ã¦ã®åˆ—ãƒ˜ãƒƒãƒ€ãƒ¼ã¨è¡Œãƒ©ãƒ™ãƒ«ã‚’ä¿æŒ
    3. æ•°å€¤ãƒ‡ãƒ¼ã‚¿ãŒæ­£ç¢ºã«ã‚­ãƒ£ãƒ—ãƒãƒ£ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª

    ãƒãƒ«ãƒã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã®å ´åˆï¼š
    1. å·¦ã‹ã‚‰å³ã¸åˆ—ã‚’å‡¦ç†
    2. ç•°ãªã‚‹åˆ—ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ˜ç¢ºã«åŒºåˆ¥

    ãƒãƒ£ãƒ¼ãƒˆã‚„ã‚°ãƒ©ãƒ•ã®å ´åˆï¼š
    1. ãƒãƒ£ãƒ¼ãƒˆã®ã‚¿ã‚¤ãƒ—ã‚’èª¬æ˜
    2. å¯è¦–ã®è»¸ãƒ©ãƒ™ãƒ«ã€å‡¡ä¾‹ã€ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’æŠ½å‡º
    3. ã‚¿ã‚¤ãƒˆãƒ«ã‚„ã‚­ãƒ£ãƒ—ã‚·ãƒ§ãƒ³ã‚’æŠ½å‡º

    ç‰¹ã«æ³¨æ„ã™ã¹ãç‚¹ï¼š
    1. ã™ã¹ã¦ã®æ•°å€¤ã®æ­£ç¢ºãªè»¢è¨˜ã‚’ç¢ºèªï¼ˆæœ€å„ªå…ˆäº‹é …ï¼‰
    2. +, -, Â±ãªã©ã®æ•°å€¤ã®å‰ã®è¨˜å·
    3. ()ã®ä¸­ã®æ–‡å­—ã¨æ•°å€¤
    4. ãƒ†ãƒ¼ãƒ–ãƒ«ã‚„æ–‡ä¸­ã«å­˜åœ¨ã™ã‚‹æ­£å¼ãªç‰©ä»¶åã¨é–¢é€£é‡‘é¡

    ã™ã¹ã¦ã®è¦‹å‡ºã—ã€ãƒ•ãƒƒã‚¿ãƒ¼ã€ãƒšãƒ¼ã‚¸ç•ªå·ã€è„šæ³¨ã‚’ç¶­æŒã—ã¦ãã ã•ã„ã€‚
    """
    
    return ocr_with_gemini(image_paths, instruction)

# ã§ã£ã‹ã„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’å‡¦ç†ã™ã‚‹
def process_large_pdf(pdf_path, output_folder, output_file, output_boxes_file):
    # ç”»åƒå¤‰æ›
    image_paths = pdf_to_images(pdf_path, output_folder)

    # ç”»åƒã‚’æ„å‘³å˜ä½ã§ä½œæˆ
    batches = batch_pdf_to_images(image_paths, 10)
    print(f"ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...")
    full_text = ""  # å¤‰æ•°ã‚’åˆæœŸåŒ–
    all_text_boxes = []
    
    for i, batch in enumerate(batches):
        print(f"ç¾åœ¨ã®å‡¦ç†ä¸­ã®ãƒãƒƒãƒï¼š{i+1}")
        special_instruction = "ã™ã¹ã¦ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã€ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ§‹é€ ã‚’ç¶­æŒ"
        result = ocr_with_gemini(batch, special_instruction)
        batch_text = result["extracted_text"]
        text_boxes = result["text_boxes"]
        
        # ãƒšãƒ¼ã‚¸ç•ªå·ã‚’è¿½åŠ 
        for box in text_boxes:
            box["page"] = i + 1
        
        all_text_boxes.extend(text_boxes)
        full_text += f"\n\n--- ãƒãƒƒãƒ {i+1} ---\n\n{batch_text}"
    
    # å…¨ãƒ†ã‚­ã‚¹ãƒˆã®ä¿å­˜
    with open(output_file, "w", encoding='utf-8') as f:
        f.write(full_text)
        
    # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ä¿å­˜
    with open(output_boxes_file, "w", encoding='utf-8') as f:
        json.dump(all_text_boxes, f, ensure_ascii=False, indent=2)

# ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºå¾Œã®ä¸€è²«æ€§ã®ç¢ºä¿
def normalize_doc(extracted_text):
    prompt = """
    ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆã¯ã€å¤§ããª PDF ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‹ã‚‰ãƒãƒƒãƒã§æŠ½å‡ºã•ã‚Œã¾ã—ãŸã€‚
        å†…å®¹ã‚’èª¿å’Œã•ã›ã‚‹ãŸã‚ã«ï¼š
        1. ã™ã¹ã¦ã®ãƒãƒƒãƒåˆ†é›¢ãƒãƒ¼ã‚«ãƒ¼ã‚’å‰Šé™¤
        2. ä¸€è²«ã—ãŸæ›¸å¼ã‚’ç¢ºä¿
        3. ãƒãƒƒãƒå¢ƒç•Œã§ã®ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã®å•é¡Œã‚’ä¿®æ­£
        4. ãƒãƒƒãƒå¢ƒç•Œã‚’è¶ŠãˆãŸæ®µè½ã¨ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®æµã‚ŒãŒè‡ªç„¶ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        
    å…ƒã®æŠ½å‡ºã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆï¼š
    """

    response = model.generate_content(prompt + extracted_text)
    print(f"æ­£è¦åŒ–ãƒ—ãƒ­ã‚»ã‚¹ã®å›ç­”ï¼š{response}")
    return response.text

def visualize_text_boxes(image_path, text_boxes, output_path):
    """ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¦–è¦šåŒ–ã™ã‚‹"""
    # ç”»åƒã‚’é–‹ã
    image = Image.open(image_path)
    draw = ImageDraw.Draw(image)
    
    # ç”»åƒã®ã‚µã‚¤ã‚ºã‚’å–å¾—
    img_width, img_height = image.size
    
    # ãƒ©ãƒ³ãƒ€ãƒ ãªè‰²ã‚’ç”Ÿæˆã™ã‚‹é–¢æ•°
    def random_color():
        return (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))
    
    # ãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®šï¼ˆåˆ©ç”¨å¯èƒ½ãªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
    try:
        font = ImageFont.truetype("Arial.ttf", 15)
    except IOError:
        try:
            # Macã§ã¯ä»£æ›¿ãƒ•ã‚©ãƒ³ãƒˆ
            font = ImageFont.truetype("/System/Library/Fonts/Supplemental/Arial.ttf", 15)
        except IOError:
            # ãã‚Œã§ã‚‚å¤±æ•—ã—ãŸå ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ•ã‚©ãƒ³ãƒˆ
            font = ImageFont.load_default()
    
    # å„ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
    for box in text_boxes:
        # ãƒã‚¦ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒœãƒƒã‚¯ã‚¹ã®åº§æ¨™ã‚’å–å¾—ï¼ˆæ­£è¦åŒ–åº§æ¨™ã‚’å®Ÿéš›ã®ç”»åƒã‚µã‚¤ã‚ºã«å¤‰æ›ï¼‰
        if "box_2d" in box:
            y1, x1, y2, x2 = box["box_2d"]
            y1 = int(y1 * img_height / 1000)
            x1 = int(x1 * img_width / 1000)
            y2 = int(y2 * img_height / 1000)
            x2 = int(x2 * img_width / 1000)
            
            # ãƒ©ãƒ³ãƒ€ãƒ ãªè‰²ã§ãƒœãƒƒã‚¯ã‚¹ã‚’æç”»
            color = random_color()
            draw.rectangle([x1, y1, x2, y2], outline=color, width=2)
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ©ãƒ™ãƒ«ã‚’æç”»
            if "label" in box:
                text = box["label"]
                # PIL 9.0.0ä»¥é™ã§ã¯textbboxã‚’ä½¿ç”¨
                try:
                    # æ–°ã—ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³
                    text_bbox = draw.textbbox((0, 0), text, font=font)
                    text_width = text_bbox[2] - text_bbox[0]
                    text_height = text_bbox[3] - text_bbox[1]
                except AttributeError:
                    # å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³å‘ã‘
                    text_width, text_height = draw.textsize(text, font=font)
                
                # ãƒ†ã‚­ã‚¹ãƒˆã®èƒŒæ™¯ã‚’æç”»
                draw.rectangle([x1, y1-text_height-4, x1+text_width+4, y1], fill=color)
                # ãƒ†ã‚­ã‚¹ãƒˆã‚’æç”»
                draw.text((x1+2, y1-text_height-2), text, fill="white", font=font)
    
    # è¦–è¦šåŒ–ã—ãŸç”»åƒã‚’ä¿å­˜
    image.save(output_path)
    print(f"è¦–è¦šåŒ–ã•ã‚ŒãŸç”»åƒã‚’ä¿å­˜ã—ã¾ã—ãŸ: {output_path}")
    return image

def visualize_all_pages(image_folder, text_boxes_file, output_folder):
    """ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’è¦–è¦šåŒ–ã™ã‚‹"""
    # å‡ºåŠ›ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
        
    # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹æƒ…å ±ã‚’èª­ã¿è¾¼ã‚€
    with open(text_boxes_file, 'r', encoding='utf-8') as f:
        all_text_boxes = json.load(f)
        
    # ãƒšãƒ¼ã‚¸ã”ã¨ã«ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    pages_boxes = {}
    for box in all_text_boxes:
        if "page" in box:
            page = box["page"]
            if page not in pages_boxes:
                pages_boxes[page] = []
            pages_boxes[page].append(box)
            
    # å„ãƒšãƒ¼ã‚¸ã®ç”»åƒã«å¯¾ã—ã¦è¦–è¦šåŒ–ã‚’å®Ÿè¡Œ
    image_files = sorted([f for f in os.listdir(image_folder) if f.endswith('.jpg')])
    
    for i, image_file in enumerate(image_files):
        page = i + 1  # ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ1ã‹ã‚‰å§‹ã¾ã‚‹ï¼‰
        image_path = os.path.join(image_folder, image_file)
        output_path = os.path.join(output_folder, f"visualized_page_{page}.jpg")
        
        # ã“ã®ãƒšãƒ¼ã‚¸ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’å–å¾—
        if page in pages_boxes:
            page_boxes = pages_boxes[page]
            # è¦–è¦šåŒ–ã‚’å®Ÿè¡Œ
            visualize_text_boxes(image_path, page_boxes, output_path)
        else:
            print(f"ãƒšãƒ¼ã‚¸ {page} ã®ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    print(f"ã™ã¹ã¦ã®ãƒšãƒ¼ã‚¸ã®è¦–è¦šåŒ–ãŒå®Œäº†ã—ã¾ã—ãŸã€‚çµæœã¯ {output_folder} ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

def main():
    pdf_path = "./data/raw_pdf/luxscape.pdf" # å‡¦ç†ã™ã‚‹PDFã®ãƒ‘ã‚¹
    output_folder = "./data/output_images" # ç”»åƒã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    output_file = "./data/content/luxscape.txt" # æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
    output_file_normalized = "./data/content/luxscape_normalized.txt" # æ­£è¦åŒ–ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
    output_boxes_file = "./data/content/luxscape_text_boxes.json" # ãƒ†ã‚­ã‚¹ãƒˆã®ä½ç½®æƒ…å ±ã‚’ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«
    visualization_folder = "./data/visualization" # è¦–è¦šåŒ–çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
    for folder in [os.path.dirname(output_file), visualization_folder]:
        if not os.path.exists(folder):
            os.makedirs(folder)

    # pdfã‚’ç”»åƒã¸å¤‰æ›
    image_paths = pdf_to_images(pdf_path, output_folder)
    print(f"ç”»åƒã®ãƒ‘ã‚¹ï¼š{image_paths}")
    
    # ç”»åƒæ•°ãŒå¤šã„å ´åˆã¯process_large_pdfã‚’ä½¿ç”¨
    if len(image_paths) > 3:  # ä¾‹ãˆã°3ãƒšãƒ¼ã‚¸ä»¥ä¸Šã®å ´åˆ
        print(f"å¤§ããªãƒšãƒ¼ã‚¸æ•°ã®PDFã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™...")
        process_large_pdf(pdf_path, output_folder, output_file, output_boxes_file)
        
        # ä¿å­˜ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§æ­£è¦åŒ–
        with open(output_file, "r", encoding='utf-8') as f:
            extracted_text = f.read()
    else:
        # å°‘ãªã„ãƒšãƒ¼ã‚¸æ•°ã®å ´åˆã¯ç›´æ¥å‡¦ç†
        result = ocr_complex_document(image_paths)
        extracted_text = result["extracted_text"]
        text_boxes = result["text_boxes"]
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¿å­˜
        with open(output_file, "w", encoding='utf-8') as f:
            f.write(extracted_text)
            
        # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã‚’ä¿å­˜
        with open(output_boxes_file, "w", encoding='utf-8') as f:
            json.dump(text_boxes, f, ensure_ascii=False, indent=2)

    # ãƒ†ã‚­ã‚¹ãƒˆã®æ­£è¦åŒ–
    normalized_text = normalize_doc(extracted_text)

    # ä¿å­˜
    with open(output_file_normalized, "w", encoding='utf-8') as f:
        f.write(normalized_text)

    # ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®è¦–è¦šåŒ–
    visualize_all_pages(output_folder, output_boxes_file, visualization_folder)

    print(f"ğŸ˜†å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸğŸ‰\nãƒ†ã‚­ã‚¹ãƒˆã¯ {output_file} & {output_file_normalized}ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    print(f"ãƒ†ã‚­ã‚¹ãƒˆãƒœãƒƒã‚¯ã‚¹ã®ä½ç½®æƒ…å ±ã¯ {output_boxes_file}ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")
    print(f"è¦–è¦šåŒ–ã•ã‚ŒãŸçµæœã¯ {visualization_folder}ã«ä¿å­˜ã•ã‚Œã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()